async def process_adk_streaming_response(
    self,
    adk_response: AsyncGenerator,                  # ADK Runner.run_async(...) çš„è¿”å›
    thread_id: str,
    prompt_messages: List[Dict[str, Any]],
    llm_model: str,
    config: ProcessorConfig = ProcessorConfig(),
    can_auto_continue: bool = False,
    auto_continue_count: int = 0,
    continuous_state: Optional[Dict[str, Any]] = None,
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    é€‚é… Google ADK äº‹ä»¶æµçš„å¤„ç†å™¨ï¼š
    - æŒ‰äº‹ä»¶ç²’åº¦äº§å‡ºâ€œchunkâ€ï¼Œå¹¶åœ¨ metadata ä¸­æ ‡æ³¨ ADK çŠ¶æ€
    - ä¸ä¾èµ– finish_reasonï¼›ä»¥ event.is_final_response() / event.partial / actions / long_running_tool_ids è®°å½•çŠ¶æ€
    - æ±‡æ€» usage_metadataï¼ˆé€šå¸¸å‡ºç°åœ¨æœ€ç»ˆäº‹ä»¶ä¸Šï¼‰
    - å¯ä¸ç°æœ‰ XML å·¥å…·è°ƒç”¨/æœ¬åœ°å·¥å…·ç­–ç•¥å…±å­˜ï¼ˆä¿æŒå ä½é€»è¾‘ï¼Œä¾¿äºä½ åç»­æ¥å…¥ï¼‰
    """

    import json, uuid, traceback
    from datetime import datetime, timezone

    def format_for_yield(msg_obj: Dict[str, Any]) -> Dict[str, Any]:
        # ä½ é¡¹ç›®é‡Œå·²æœ‰çš„å·¥å…·æ–¹æ³•ï¼Œè¿™é‡Œåšä¸ªå…œåº•
        return msg_obj

    def _now_ts():
        return datetime.now(timezone.utc).timestamp()

    def _safe_text(x) -> str:
        # è§„é¿â€œcan only concatenate str (not 'list') to strâ€
        if isinstance(x, str):
            return x
        if isinstance(x, (list, tuple)):
            return "".join(str(t) for t in x)
        return str(x)

    def _event_is_final(e) -> bool:
        try:
            # ADK æä¾›çš„æœ€ç»ˆå“åº”åˆ¤å®š
            return bool(getattr(e, "is_final_response", None) and e.is_final_response())
        except Exception:
            # å›é€€é€»è¾‘ï¼špartial==False ä¸”æœ‰ usage_metadata æ—¶å¤§æ¦‚ç‡ä¸ºæœ€ç»ˆ
            return bool(getattr(e, "partial", None) is False and getattr(e, "usage_metadata", None) is not None)

    # ============ åˆå§‹åŒ– ============
    continuous_state = continuous_state or {}
    thread_run_id = continuous_state.get('thread_run_id') or str(uuid.uuid4())
    continuous_state['thread_run_id'] = thread_run_id

    accumulated_content = continuous_state.get('accumulated_content', "")
    xml_ongoing_buffer = continuous_state.get('xml_ongoing_buffer', "")
    __sequence = int(continuous_state.get('sequence', 0))

    # å·¥å…·ç›¸å…³ï¼ˆå¦‚æœä½ å¼€å¯äº† XML æˆ– Native å·¥å…·ï¼‰
    xml_chunks_buffer = []
    complete_native_tool_calls = []
    tool_result_message_objects = {}

    usage_snapshot = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
    finish_reason = None           # ä¸ä½œä¸ºæµæ§åˆ¶ï¼Œä»…ç”¨äºæœ€åè®°å½•
    saw_error = False
    saw_length_limit = False

    streaming_metadata = {
        "model": llm_model,
        "created": int(_now_ts()),
        "usage": usage_snapshot,
        "response_ms": None,
        "first_chunk_time": None,
        "last_chunk_time": None,
    }

    print(
        f"ADK Streaming Config: XML={config.xml_tool_calling}, "
        f"Native={config.native_tool_calling}, Execute on stream={config.execute_on_stream}, "
        f"Strategy={config.tool_execution_strategy}"
    )
    print("è¿™æ˜¯æˆ‘thread_run_idçš„å€¼", thread_run_id)

    # ============ï¼ˆå¯é€‰ï¼‰å¼€å§‹äº‹ä»¶ ============
    # å¦‚éœ€æ¢å¤åŸå…ˆçš„â€œå¼€å§‹çŠ¶æ€æ¶ˆæ¯â€ï¼Œå¯å–æ¶ˆæ³¨é‡Š
    # if auto_continue_count == 0:
    #     start_msg = await self.add_message(thread_id, "status",
    #         {"status_type": "thread_run_start", "thread_run_id": thread_run_id},
    #         is_llm_message=False, metadata={"thread_run_id": thread_run_id})
    #     if start_msg: yield format_for_yield(start_msg)
    #     assist_start = await self.add_message(thread_id, "status",
    #         {"status_type": "assistant_response_start"},
    #         is_llm_message=False, metadata={"thread_run_id": thread_run_id})
    #     if assist_start: yield format_for_yield(assist_start)

    try:
        print("ğŸ” [ADK PROCESSOR DEBUG] å¼€å§‹å¤„ç† ADK äº‹ä»¶...")

        async for event in adk_response:
            # ===== åŸºæœ¬æ—¶åºå…ƒæ•°æ® =====
            now_ts = _now_ts()
            if streaming_metadata["first_chunk_time"] is None:
                streaming_metadata["first_chunk_time"] = now_ts
            streaming_metadata["last_chunk_time"] = now_ts

            # ===== usageï¼ˆè‹¥å‡ºç°å°±æ›´æ–°ï¼›é€šå¸¸æœ€ç»ˆäº‹ä»¶ä¸Šæ‰æœ‰ï¼‰=====
            um = getattr(event, "usage_metadata", None)
            if um:
                # GenerateContentResponseUsageMetadata: candidates_token_count / prompt_token_count / total_token_count
                usage_snapshot["prompt_tokens"] = getattr(um, "prompt_token_count", usage_snapshot["prompt_tokens"])
                usage_snapshot["completion_tokens"] = getattr(um, "candidates_token_count", usage_snapshot["completion_tokens"])
                usage_snapshot["total_tokens"] = getattr(um, "total_token_count", usage_snapshot["total_tokens"])

            # ===== é”™è¯¯ & æˆªæ–­æ¢æµ‹ï¼ˆADK çš„é”™è¯¯ç /æ¶ˆæ¯ï¼‰=====
            error_code = getattr(event, "error_code", None)
            error_msg = getattr(event, "error_message", None)
            if error_code:
                saw_error = True
                # çº¦å®šï¼šå¦‚æœé”™è¯¯ç ç­‰ä»·äº token æˆªæ–­
                if str(error_code).upper() in {"MAX_TOKENS", "TOKEN_LIMIT", "LENGTH"}:
                    saw_length_limit = True

            # ===== äº‹ä»¶å±‚é¢çš„â€œçŠ¶æ€ä½â€ =====
            partial = getattr(event, "partial", None)
            turn_complete = getattr(event, "turn_complete", None)
            is_final = _event_is_final(event)

            # ADK çš„åŠ¨ä½œï¼ˆç§»äº¤ã€å‡çº§ã€çŠ¶æ€/å·¥ä»¶ deltaã€é‰´æƒè¯·æ±‚ç­‰ï¼‰
            actions = getattr(event, "actions", None)
            long_run_tools = list(getattr(event, "long_running_tool_ids", []) or [])

            # ä¸ºæ¯ä¸ª chunk è®¡ç®—â€œæ‰€å¤„çŠ¶æ€â€
            def _derive_chunk_status() -> str:
                if error_code:
                    return "error"
                if long_run_tools:
                    return "tool_running"
                # ç§»äº¤/å‡çº§å…·å¤‡ä¼˜å…ˆçº§æ ‡è®°
                if actions and (getattr(actions, "transfer_to_agent", None) or getattr(actions, "escalate", None)):
                    return "handover"
                if is_final:
                    return "final"
                if partial is True:
                    return "delta"
                if partial is False:
                    # éæµå¼å•å‘ or æœªæ ‡æ³¨ usage çš„å°¾åŒ…
                    return "possibly_final"
                return "unknown"

            chunk_status = _derive_chunk_status()

            # ===== å†…å®¹å¢é‡äº§å‡º =====
            content = getattr(event, "content", None)
            if content and getattr(content, "parts", None):
                try:
                    for part in content.parts:
                        text = getattr(part, "text", None)
                        if text is None:
                            # å¯èƒ½æ˜¯å…¶ä»– Part å½¢æ€ï¼ˆå¦‚ inlineData ç­‰ï¼‰ï¼›è¿™é‡Œç»Ÿä¸€è½¬æˆå­—ç¬¦ä¸²
                            text = _safe_text(getattr(part, "to_dict", lambda: str(part))())
                        text = _safe_text(text)
                        if not text:
                            continue

                        # ç´¯ç§¯æ€»å†…å®¹ï¼ˆç”¨äºæœ€ç»ˆå…¥åº“ï¼‰
                        accumulated_content += text
                        xml_ongoing_buffer += text  # ç»™ XML å·¥å…·è§£æç•™å£å­

                        # äº§å‡ºâ€œassistantâ€æµå¼ç‰‡æ®µï¼Œå¹¶æŠŠ ADK çŠ¶æ€æ‰“åœ¨ metadata ä¸Š
                        msg_obj = {
                            "sequence": __sequence,
                            "message_id": None,
                            "thread_id": thread_id,
                            "type": "assistant",
                            "is_llm_message": True,
                            "content": json.dumps({"role": "assistant", "content": text}, ensure_ascii=False),
                            "metadata": json.dumps({
                                "thread_run_id": thread_run_id,
                                "stream_status": chunk_status,      # <=== å…³é”®ï¼šchunk æ‰€å¤„çŠ¶æ€
                                "adk": {
                                    "event_id": getattr(event, "id", None),
                                    "invocation_id": getattr(event, "invocation_id", None),
                                    "author": getattr(event, "author", None),
                                    "timestamp": getattr(event, "timestamp", None),
                                    "partial": partial,
                                    "turn_complete": turn_complete,
                                    "is_final_response": is_final,
                                    "error_code": error_code,
                                    "error_message": error_msg,
                                    "long_running_tool_ids": long_run_tools,
                                    "actions": {
                                        "transfer_to_agent": getattr(actions, "transfer_to_agent", None) if actions else None,
                                        "escalate": getattr(actions, "escalate", None) if actions else None,
                                        "state_delta": getattr(actions, "state_delta", None) if actions else None,
                                        "artifact_delta": getattr(actions, "artifact_delta", None) if actions else None,
                                        "requested_auth_configs": getattr(actions, "requested_auth_configs", None) if actions else None,
                                    },
                                }
                            }, ensure_ascii=False),
                        }
                        yield msg_obj
                        __sequence += 1

                except Exception as ie:
                    # å†…å®¹å¤„ç†å¼‚å¸¸ä¹Ÿè¦ç»§ç»­è¿›è¡Œï¼ˆå¹¶ä¸”è®©ä¸Šå±‚çœ‹åˆ°é”™è¯¯çŠ¶æ€ï¼‰
                    err_msg = await self.add_message(
                        thread_id=thread_id,
                        type="status",
                        content={"status_type": "error", "message": f"Error handling content parts: {ie}"},
                        is_llm_message=False,
                        metadata={"thread_run_id": thread_run_id},
                    )
                    if err_msg:
                        yield format_for_yield(err_msg)

            # =====ï¼ˆå¯é€‰ï¼‰XML å·¥å…·è°ƒç”¨è§£æï¼ˆä¿ç•™å ä½ï¼Œæ²¿ç”¨ä½ å·²æœ‰è§£æå™¨ï¼‰=====
            if config.xml_tool_calling and xml_ongoing_buffer:
                # TODO: è¿™é‡Œæ¥ä½ ç°æœ‰çš„ XML è§£æé€»è¾‘ï¼ŒæŠŠè§£æå‡ºçš„ tool_calls ä»¥â€œå·¥å…·è°ƒç”¨ç‰‡æ®µ/å®Œæˆâ€å½¢å¼äº§å‡º
                # xml_chunks = parse_xml_from_buffer(xml_ongoing_buffer)  # ä¼ªä»£ç 
                # for tool_call in xml_chunks: yield {... "stream_status": "tool_call_chunk" ...}
                pass

            # ===== äº‹ä»¶å±‚é¢çš„çŠ¶æ€/å·¥ä»¶å¢é‡ï¼Œä¹Ÿå¯ä»¥å•ç‹¬è½ä¸€æ¡çŠ¶æ€æ¶ˆæ¯ï¼Œä¾¿äºå‰ç«¯ UI æ ‡æ³¨ =====
            if actions and (getattr(actions, "state_delta", None) or getattr(actions, "artifact_delta", None)):
                state_msg = await self.add_message(
                    thread_id=thread_id,
                    type="status",
                    content={
                        "status_type": "agent_state_delta",
                        "state_delta": getattr(actions, "state_delta", None),
                        "artifact_delta": getattr(actions, "artifact_delta", None),
                    },
                    is_llm_message=False,
                    metadata={"thread_run_id": thread_run_id},
                )
                if state_msg:
                    yield format_for_yield(state_msg)

            # ===== è®°å½•â€œæœ€ç»ˆäº‹ä»¶â€æ—¶çš„ finish_reasonï¼ˆä»…ç”¨äºå­˜æ¡£/å¯è§†åŒ–ï¼Œä¸ç”¨äºæµæ§åˆ¶ï¼‰=====
            # ADK ä¸ä¿è¯ä¸€å®šæä¾› finish_reasonï¼›æ­¤å¤„åªåšè®°å½•
            fr = getattr(event, "finish_reason", None)
            if fr:
                finish_reason = str(fr)

        # ===== æµç»“æŸï¼šä¿å­˜å®Œæ•´åŠ©æ‰‹æ¶ˆæ¯ & ç»“æŸäº‹ä»¶ =====
        # æ ¹æ® ADK è®¾è®¡ï¼Œæœ€ç»ˆæ€§åº”ä»¥ is_final_response åˆ¤å®šï¼›finish_reason å¯ç¼ºçœ
        if saw_error:
            resolved_finish = "error"
        elif saw_length_limit:
            resolved_finish = "length"
        elif finish_reason:
            resolved_finish = finish_reason
        else:
            resolved_finish = "stop"  # é»˜è®¤

        if accumulated_content.strip():
            assistant_message_obj = await self.add_message(
                thread_id=thread_id,
                type="assistant",
                content=accumulated_content,
                is_llm_message=True,
                metadata={
                    "thread_run_id": thread_run_id,
                    "model": llm_model,
                    "finish_reason": resolved_finish,
                    "usage": usage_snapshot,
                },
            )
            if assistant_message_obj:
                yield format_for_yield(assistant_message_obj)

        # ç»“æŸçŠ¶æ€ï¼ˆå¯é€‰ï¼Œä¸åŸé€»è¾‘ä¿æŒä¸€è‡´ï¼‰
        assist_end = await self.add_message(
            thread_id=thread_id,
            type="status",
            content={"status_type": "assistant_response_end"},
            is_llm_message=False,
            metadata={"thread_run_id": thread_run_id},
        )
        if assist_end:
            yield format_for_yield(assist_end)

        thread_end = await self.add_message(
            thread_id=thread_id,
            type="status",
            content={"status_type": "thread_run_end", "thread_run_id": thread_run_id},
            is_llm_message=False,
            metadata={"thread_run_id": thread_run_id},
        )
        if thread_end:
            yield format_for_yield(thread_end)

        print("âœ… [ADK PROCESSOR DEBUG] ADK æµå¼å“åº”å¤„ç†å®Œæˆ")

    except Exception as e:
        traceback.print_exc()
        err = await self.add_message(
            thread_id=thread_id,
            type="status",
            content={"status_type": "error", "message": f"Error during ADK response streaming: {e}"},
            is_llm_message=False,
            metadata={"thread_run_id": thread_run_id},
        )
        if err:
            yield format_for_yield(err)
        raise
