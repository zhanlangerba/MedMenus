import os
import json
import asyncio
import datetime
from typing import Optional, Dict, List, Any, AsyncGenerator
from dataclasses import dataclass
import traceback


from agent.tools.message_tool import MessageTool
# from agent.tools.sb_deploy_tool import SandboxDeployTool
# from agent.tools.sb_expose_tool import SandboxExposeTool
# from agent.tools.web_search_tool import SandboxWebSearchTool
from dotenv import load_dotenv # type: ignore
from utils.config import config
# from agent.agent_builder_prompt import get_agent_builder_prompt
from agentpress.thread_manager import ThreadManager
from agentpress.response_processor import ProcessorConfig
# from agent.tools.sb_shell_tool import SandboxShellTool
# from agent.tools.sb_files_tool import SandboxFilesTool
#from agent.tools.data_providers_tool import DataProvidersTool
# from agent.tools.expand_msg_tool import ExpandMessageTool
from agent.prompt import get_system_prompt
from agent.gemini_prompt import get_gemini_system_prompt
# from agent.custom_prompt import render_prompt_template
from utils.logger import logger
# from utils.auth_utils import get_account_id_from_thread
# from services.billing import check_billing_status
# from agent.tools.sb_vision_tool import SandboxVisionTool
# from agent.tools.sb_image_edit_tool import SandboxImageEditTool
# from agent.tools.sb_presentation_outline_tool import SandboxPresentationOutlineTool
# from agent.tools.sb_presentation_tool_v2 import SandboxPresentationToolV2
from services.langfuse import langfuse
try:
    from langfuse.client import StatefulTraceClient # type: ignore
except ImportError:
    # å¯¹äº langfuse 3.x ç‰ˆæœ¬ï¼Œå°è¯•ä¸åŒçš„å¯¼å…¥è·¯å¾„
    try:
        from langfuse import StatefulTraceClient # type: ignore
    except ImportError:
        # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨ Any ç±»å‹
        from typing import Any
        StatefulTraceClient = Any

# from agent.tools.mcp_tool_wrapper import MCPToolWrapper
# from agent.tools.task_list_tool import TaskListTool
# from agentpress.tool import SchemaType
# from agent.tools.sb_sheets_tool import SandboxSheetsTool
# from agent.tools.sb_web_dev_tool import SandboxWebDevTool

load_dotenv()


@dataclass
class AgentConfig:
    thread_id: str
    project_id: str
    stream: bool
    native_max_auto_continues: int = 25
    max_iterations: int = 100
    model_name: str = "deepseek/deepseek-chat"
    enable_thinking: Optional[bool] = False
    reasoning_effort: Optional[str] = 'low'
    enable_context_manager: bool = True
    agent_config: Optional[dict] = None
    trace: Optional[StatefulTraceClient] = None # type: ignore
    is_agent_builder: Optional[bool] = False
    target_agent_id: Optional[str] = None


class ToolManager:
    def __init__(self, thread_manager: ThreadManager, project_id: str, thread_id: str):
        self.thread_manager = thread_manager
        self.project_id = project_id
        self.thread_id = thread_id
    
    def register_all_tools(self):
        # ğŸ§ª æµ‹è¯•ç°æœ‰å·¥å…·æ³¨å†Œæµç¨‹
        from agent.tools.simple_test_tool import SimpleTestTool
        self.thread_manager.add_tool(SimpleTestTool)

        from agent.tools.task_list_tool_simple import TaskListToolSimple
        self.thread_manager.add_tool(TaskListToolSimple, project_id=self.project_id, thread_manager=self.thread_manager, thread_id=self.thread_id)
        logger.info("Successfully registered task list tool: TaskListTool (with enhanced registry)")
        
        # self.thread_manager.add_tool(SandboxShellTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(SandboxFilesTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(SandboxDeployTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(SandboxExposeTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(SandboxWebSearchTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(SandboxVisionTool, project_id=self.project_id, thread_id=self.thread_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(SandboxImageEditTool, project_id=self.project_id, thread_id=self.thread_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(SandboxPresentationOutlineTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(SandboxPresentationToolV2, project_id=self.project_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(TaskListTool, project_id=self.project_id, thread_manager=self.thread_manager, thread_id=self.thread_id)
        # self.thread_manager.add_tool(SandboxSheetsTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(SandboxWebDevTool, project_id=self.project_id, thread_id=self.thread_id, thread_manager=self.thread_manager)
        # if config.RAPID_API_KEY:
        #     self.thread_manager.add_tool(DataProvidersTool)
        

        
        # # Add Browser Tool
        # from agent.tools.browser_tool import BrowserTool
        # self.thread_manager.add_tool(BrowserTool, project_id=self.project_id, thread_id=self.thread_id, thread_manager=self.thread_manager)
    
    def register_agent_builder_tools(self, agent_id: str):
        pass
        # from agent.tools.agent_builder_tools.agent_config_tool import AgentConfigTool
        # from agent.tools.agent_builder_tools.mcp_search_tool import MCPSearchTool
        # from agent.tools.agent_builder_tools.credential_profile_tool import CredentialProfileTool
        # from agent.tools.agent_builder_tools.workflow_tool import WorkflowTool
        # from agent.tools.agent_builder_tools.trigger_tool import TriggerTool
        # from services.postgresql import DBConnection
        
        # db = DBConnection()
        # self.thread_manager.add_tool(AgentConfigTool, thread_manager=self.thread_manager, db_connection=db, agent_id=agent_id)
        # self.thread_manager.add_tool(MCPSearchTool, thread_manager=self.thread_manager, db_connection=db, agent_id=agent_id)
        # self.thread_manager.add_tool(CredentialProfileTool, thread_manager=self.thread_manager, db_connection=db, agent_id=agent_id)
        # self.thread_manager.add_tool(WorkflowTool, thread_manager=self.thread_manager, db_connection=db, agent_id=agent_id)
        # self.thread_manager.add_tool(TriggerTool, thread_manager=self.thread_manager, db_connection=db, agent_id=agent_id)
    
    def register_custom_tools(self, enabled_tools: Dict[str, Any]):
        pass
        # self.thread_manager.add_tool(ExpandMessageTool, thread_id=self.thread_id, thread_manager=self.thread_manager)
        # self.thread_manager.add_tool(MessageTool)
        # self.thread_manager.add_tool(TaskListTool, project_id=self.project_id, thread_manager=self.thread_manager, thread_id=self.thread_id)

        # def safe_tool_check(tool_name: str) -> bool:
        #     try:
        #         if not isinstance(enabled_tools, dict):
        #             return False
        #         tool_config = enabled_tools.get(tool_name, {})
        #         if not isinstance(tool_config, dict):
        #             return bool(tool_config) if isinstance(tool_config, bool) else False
        #         return tool_config.get('enabled', False)
        #     except Exception:
        #         return False
        
        # if safe_tool_check('sb_shell_tool'):
        #     self.thread_manager.add_tool(SandboxShellTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # if safe_tool_check('sb_files_tool'):
        #     self.thread_manager.add_tool(SandboxFilesTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # if safe_tool_check('sb_deploy_tool'):
        #     self.thread_manager.add_tool(SandboxDeployTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # if safe_tool_check('sb_expose_tool'):
        #     self.thread_manager.add_tool(SandboxExposeTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # if safe_tool_check('web_search_tool'):
        #     self.thread_manager.add_tool(SandboxWebSearchTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # if safe_tool_check('sb_vision_tool'):
        #     self.thread_manager.add_tool(SandboxVisionTool, project_id=self.project_id, thread_id=self.thread_id, thread_manager=self.thread_manager)
        # if safe_tool_check('sb_presentation_tool'):
        #     self.thread_manager.add_tool(SandboxPresentationOutlineTool, project_id=self.project_id, thread_manager=self.thread_manager)
        #     self.thread_manager.add_tool(SandboxPresentationToolV2, project_id=self.project_id, thread_manager=self.thread_manager)
        # if safe_tool_check('sb_image_edit_tool'):
        #     self.thread_manager.add_tool(SandboxImageEditTool, project_id=self.project_id, thread_id=self.thread_id, thread_manager=self.thread_manager)
        # if safe_tool_check('sb_sheets_tool'):
        #     self.thread_manager.add_tool(SandboxSheetsTool, project_id=self.project_id, thread_manager=self.thread_manager)
        # if safe_tool_check('sb_web_dev_tool'):
        #     self.thread_manager.add_tool(SandboxWebDevTool, project_id=self.project_id, thread_id=self.thread_id, thread_manager=self.thread_manager)
        # if config.RAPID_API_KEY and safe_tool_check('data_providers_tool'):
        #     self.thread_manager.add_tool(DataProvidersTool)

        
        # if safe_tool_check('browser_tool'):
        #     from agent.tools.browser_tool import BrowserTool
        #     self.thread_manager.add_tool(BrowserTool, project_id=self.project_id, thread_id=self.thread_id, thread_manager=self.thread_manager)


# class MCPManager:
#     def __init__(self, thread_manager: ThreadManager, account_id: str):
#         self.thread_manager = thread_manager
#         self.account_id = account_id
    
#     async def register_mcp_tools(self, agent_config: dict) -> Optional[MCPToolWrapper]:
#         all_mcps = []
        
#         if agent_config.get('configured_mcps'):
#             all_mcps.extend(agent_config['configured_mcps'])
        
#         if agent_config.get('custom_mcps'):
#             for custom_mcp in agent_config['custom_mcps']:
#                 custom_type = custom_mcp.get('customType', custom_mcp.get('type', 'sse'))
                
#                 if custom_type == 'pipedream':
#                     if 'config' not in custom_mcp:
#                         custom_mcp['config'] = {}
                    
#                     if not custom_mcp['config'].get('external_user_id'):
#                         profile_id = custom_mcp['config'].get('profile_id')
#                         if profile_id:
#                             try:
#                                 from pipedream import profile_service
#                                 from uuid import UUID
                                
#                                 profile = await profile_service.get_profile(UUID(self.account_id), UUID(profile_id))
#                                 if profile:
#                                     custom_mcp['config']['external_user_id'] = profile.external_user_id
#                             except Exception as e:
#                                 logger.error(f"Error retrieving external_user_id from profile {profile_id}: {e}")
                    
#                     if 'headers' in custom_mcp['config'] and 'x-pd-app-slug' in custom_mcp['config']['headers']:
#                         custom_mcp['config']['app_slug'] = custom_mcp['config']['headers']['x-pd-app-slug']
                
#                 elif custom_type == 'composio':
#                     qualified_name = custom_mcp.get('qualifiedName')
#                     if not qualified_name:
#                         qualified_name = f"composio.{custom_mcp['name'].replace(' ', '_').lower()}"
                    
#                     mcp_config = {
#                         'name': custom_mcp['name'],
#                         'qualifiedName': qualified_name,
#                         'config': custom_mcp.get('config', {}),
#                         'enabledTools': custom_mcp.get('enabledTools', []),
#                         'instructions': custom_mcp.get('instructions', ''),
#                         'isCustom': True,
#                         'customType': 'composio'
#                     }
#                     all_mcps.append(mcp_config)
#                     continue
                
#                 mcp_config = {
#                     'name': custom_mcp['name'],
#                     'qualifiedName': f"custom_{custom_type}_{custom_mcp['name'].replace(' ', '_').lower()}",
#                     'config': custom_mcp['config'],
#                     'enabledTools': custom_mcp.get('enabledTools', []),
#                     'instructions': custom_mcp.get('instructions', ''),
#                     'isCustom': True,
#                     'customType': custom_type
#                 }
#                 all_mcps.append(mcp_config)
        
#         if not all_mcps:
#             return None
        
#         mcp_wrapper_instance = MCPToolWrapper(mcp_configs=all_mcps)
#         try:
#             await mcp_wrapper_instance.initialize_and_register_tools()
            
#             updated_schemas = mcp_wrapper_instance.get_schemas()
#             for method_name, schema_list in updated_schemas.items():
#                 for schema in schema_list:
#                     self.thread_manager.tool_registry.tools[method_name] = {
#                         "instance": mcp_wrapper_instance,
#                         "schema": schema
#                     }
            
#             logger.info(f"âš¡ Registered {len(updated_schemas)} MCP tools (Redis cache enabled)")
#             return mcp_wrapper_instance
#         except Exception as e:
#             logger.error(f"Failed to initialize MCP tools: {e}")
#             return None


class PromptManager:
    @staticmethod
    # async def build_system_prompt(model_name: str, agent_config: Optional[dict], 
    #                               is_agent_builder: bool, thread_id: str, 
    #                               mcp_wrapper_instance: Optional[MCPToolWrapper]) -> dict:
    async def build_system_prompt(model_name: str, agent_config: Optional[dict], 
                                  is_agent_builder: bool, thread_id: str, ) -> dict:    
        if "gemini-2.5-flash" in model_name.lower() and "gemini-2.5-pro" not in model_name.lower():
            default_system_content = get_gemini_system_prompt()
        else:
            default_system_content = get_system_prompt()
        
        # if "anthropic" not in model_name.lower():
        #     sample_response_path = os.path.join(os.path.dirname(__file__), 'sample_responses/1.txt')
        #     with open(sample_response_path, 'r') as file:
        #         sample_response = file.read()
        #     default_system_content = default_system_content + "\n\n <sample_assistant_response>" + sample_response + "</sample_assistant_response>"
        
        # if is_agent_builder:
        #     system_content = get_agent_builder_prompt()
        # elif agent_config and agent_config.get('system_prompt'):
        #     system_content = render_prompt_template(agent_config['system_prompt'].strip())
        # else:
        #    system_content = default_system_content
        system_content = default_system_content
        # if agent_config and (agent_config.get('configured_mcps') or agent_config.get('custom_mcps')) and mcp_wrapper_instance and mcp_wrapper_instance._initialized:
        #     mcp_info = "\n\n--- MCP Tools Available ---\n"
        #     mcp_info += "You have access to external MCP (Model Context Protocol) server tools.\n"
        #     mcp_info += "MCP tools can be called directly using their native function names in the standard function calling format:\n"
        #     mcp_info += '<function_calls>\n'
        #     mcp_info += '<invoke name="{tool_name}">\n'
        #     mcp_info += '<parameter name="param1">value1</parameter>\n'
        #     mcp_info += '<parameter name="param2">value2</parameter>\n'
        #     mcp_info += '</invoke>\n'
        #     mcp_info += '</function_calls>\n\n'
            
        #     mcp_info += "Available MCP tools:\n"
        #     try:
        #         registered_schemas = mcp_wrapper_instance.get_schemas()
        #         for method_name, schema_list in registered_schemas.items():
        #             for schema in schema_list:
        #                 if schema.schema_type == SchemaType.OPENAPI:
        #                     func_info = schema.schema.get('function', {})
        #                     description = func_info.get('description', 'No description available')
        #                     mcp_info += f"- **{method_name}**: {description}\n"
                            
        #                     params = func_info.get('parameters', {})
        #                     props = params.get('properties', {})
        #                     if props:
        #                         mcp_info += f"  Parameters: {', '.join(props.keys())}\n"
                                
        #     except Exception as e:
        #         logger.error(f"Error listing MCP tools: {e}")
        #         mcp_info += "- Error loading MCP tool list\n"
            
        #     mcp_info += "\nğŸš¨ CRITICAL MCP TOOL RESULT INSTRUCTIONS ğŸš¨\n"
        #     mcp_info += "When you use ANY MCP (Model Context Protocol) tools:\n"
        #     mcp_info += "1. ALWAYS read and use the EXACT results returned by the MCP tool\n"
        #     mcp_info += "2. For search tools: ONLY cite URLs, sources, and information from the actual search results\n"
        #     mcp_info += "3. For any tool: Base your response entirely on the tool's output - do NOT add external information\n"
        #     mcp_info += "4. DO NOT fabricate, invent, hallucinate, or make up any sources, URLs, or data\n"
        #     mcp_info += "5. If you need more information, call the MCP tool again with different parameters\n"
        #     mcp_info += "6. When writing reports/summaries: Reference ONLY the data from MCP tool results\n"
        #     mcp_info += "7. If the MCP tool doesn't return enough information, explicitly state this limitation\n"
        #     mcp_info += "8. Always double-check that every fact, URL, and reference comes from the MCP tool output\n"
        #     mcp_info += "\nIMPORTANT: MCP tool results are your PRIMARY and ONLY source of truth for external data!\n"
        #     mcp_info += "NEVER supplement MCP results with your training data or make assumptions beyond what the tools provide.\n"
            
        #     system_content += mcp_info

        now = datetime.datetime.now(datetime.timezone.utc)
        datetime_info = f"\n\n=== CURRENT DATE/TIME INFORMATION ===\n"
        datetime_info += f"Today's date: {now.strftime('%A, %B %d, %Y')}\n"
        datetime_info += f"Current UTC time: {now.strftime('%H:%M:%S UTC')}\n"
        datetime_info += f"Current year: {now.strftime('%Y')}\n"
        datetime_info += f"Current month: {now.strftime('%B')}\n"
        datetime_info += f"Current day: {now.strftime('%A')}\n"
        datetime_info += "Use this information for any time-sensitive tasks, research, or when current date/time context is needed.\n"
        
        system_content += datetime_info

        return {"role": "system", "content": system_content}

class MessageManager:
    """
    æ¶ˆæ¯ç®¡ç†å™¨ç±»
    
    è´Ÿè´£æ„å»ºä¸´æ—¶æ¶ˆæ¯ï¼ŒåŒ…æ‹¬æµè§ˆå™¨çŠ¶æ€å’Œå›¾åƒä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
    è¿™äº›ä¸´æ—¶æ¶ˆæ¯ä¼šåœ¨AIå¤„ç†ç”¨æˆ·è¯·æ±‚æ—¶ä½œä¸ºä¸Šä¸‹æ–‡ä¿¡æ¯æä¾›ç»™æ¨¡å‹ã€‚
    """
    
    def __init__(self, client, thread_id: str, model_name: str, trace: Optional[StatefulTraceClient]): # type: ignore
        """
        åˆå§‹åŒ–æ¶ˆæ¯ç®¡ç†å™¨
        
        Args:
            client: æ•°æ®åº“å®¢æˆ·ç«¯ï¼Œç”¨äºæŸ¥è¯¢æ¶ˆæ¯è¡¨
            thread_id: çº¿ç¨‹IDï¼Œç”¨äºæ ‡è¯†ç‰¹å®šçš„å¯¹è¯çº¿ç¨‹
            model_name: æ¨¡å‹åç§°ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦æ”¯æŒå›¾åƒå¤„ç†
            trace: è¿½è¸ªå®¢æˆ·ç«¯ï¼Œç”¨äºæ—¥å¿—è®°å½•
        """
        self.client = client
        self.thread_id = thread_id
        self.model_name = model_name
        self.trace = trace
    
    async def build_temporary_message(self) -> Optional[dict]:
        """
        æ„å»ºä¸´æ—¶æ¶ˆæ¯
        
        è¿™ä¸ªæ–¹æ³•ä¼šï¼š
        1. è·å–æœ€æ–°çš„æµè§ˆå™¨çŠ¶æ€ä¿¡æ¯ï¼ˆåŒ…æ‹¬æˆªå›¾ï¼‰
        2. è·å–æœ€æ–°çš„å›¾åƒä¸Šä¸‹æ–‡ä¿¡æ¯
        3. å°†è¿™äº›ä¿¡æ¯ç»„åˆæˆä¸€ä¸ªä¸´æ—¶æ¶ˆæ¯ï¼Œä¾›AIæ¨¡å‹ä½¿ç”¨
        
        Returns:
            Optional[dict]: åŒ…å«æµè§ˆå™¨çŠ¶æ€å’Œå›¾åƒä¿¡æ¯çš„ä¸´æ—¶æ¶ˆæ¯ï¼Œå¦‚æœæ²¡æœ‰ç›¸å…³ä¿¡æ¯åˆ™è¿”å›None
        """
        temp_message_content_list = []  # å­˜å‚¨ä¸´æ—¶æ¶ˆæ¯çš„å†…å®¹åˆ—è¡¨

        # è·å–æœ€æ–°çš„æµè§ˆå™¨çŠ¶æ€æ¶ˆæ¯
        latest_browser_state_msg = await self.client.table('messages').select('*').eq('thread_id', self.thread_id).eq('type', 'browser_state').order('created_at', desc=True).limit(1).execute()
        
        if latest_browser_state_msg.data and len(latest_browser_state_msg.data) > 0:
            try:
                # è§£ææµè§ˆå™¨çŠ¶æ€å†…å®¹
                browser_content = latest_browser_state_msg.data[0]["content"]
                if isinstance(browser_content, str):
                    browser_content = json.loads(browser_content)
                
                # æå–æˆªå›¾ä¿¡æ¯
                screenshot_base64 = browser_content.get("screenshot_base64")  # Base64ç¼–ç çš„æˆªå›¾
                screenshot_url = browser_content.get("image_url")  # æˆªå›¾çš„URLåœ°å€
                
                # å¤åˆ¶æµè§ˆå™¨çŠ¶æ€æ–‡æœ¬ï¼Œç§»é™¤æˆªå›¾ç›¸å…³å­—æ®µ
                browser_state_text = browser_content.copy()
                browser_state_text.pop('screenshot_base64', None)
                browser_state_text.pop('image_url', None)

                # å¦‚æœæœ‰æµè§ˆå™¨çŠ¶æ€æ–‡æœ¬ä¿¡æ¯ï¼Œæ·»åŠ åˆ°ä¸´æ—¶æ¶ˆæ¯ä¸­
                if browser_state_text:
                    temp_message_content_list.append({
                        "type": "text",
                        "text": f"The following is the current state of the browser:\n{json.dumps(browser_state_text, indent=2)}"
                    })
                
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒå›¾åƒå¤„ç†ï¼ˆGeminiã€Anthropicã€OpenAIï¼‰
                if 'gemini' in self.model_name.lower() or 'anthropic' in self.model_name.lower() or 'openai' in self.model_name.lower():
                    # ä¼˜å…ˆä½¿ç”¨URLï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨Base64
                    if screenshot_url:
                        temp_message_content_list.append({
                            "type": "image_url",
                            "image_url": {
                                "url": screenshot_url,
                                "format": "image/jpeg"
                            }
                        })
                    elif screenshot_base64:
                        temp_message_content_list.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{screenshot_base64}",
                            }
                        })

            except Exception as e:
                logger.error(f"Error parsing browser state: {e}")

        # è·å–æœ€æ–°çš„å›¾åƒä¸Šä¸‹æ–‡æ¶ˆæ¯
        latest_image_context_msg = await self.client.table('messages').select('*').eq('thread_id', self.thread_id).eq('type', 'image_context').order('created_at', desc=True).limit(1).execute()
        
        if latest_image_context_msg.data and len(latest_image_context_msg.data) > 0:
            try:
                # è§£æå›¾åƒä¸Šä¸‹æ–‡å†…å®¹
                image_context_content = latest_image_context_msg.data[0]["content"] if isinstance(latest_image_context_msg.data[0]["content"], dict) else json.loads(latest_image_context_msg.data[0]["content"])
                
                # æå–å›¾åƒä¿¡æ¯
                base64_image = image_context_content.get("base64")  # Base64ç¼–ç çš„å›¾åƒ
                mime_type = image_context_content.get("mime_type")  # å›¾åƒçš„MIMEç±»å‹
                file_path = image_context_content.get("file_path", "unknown file")  # å›¾åƒæ–‡ä»¶è·¯å¾„

                # å¦‚æœæœ‰å›¾åƒæ•°æ®ï¼Œæ·»åŠ åˆ°ä¸´æ—¶æ¶ˆæ¯ä¸­
                if base64_image and mime_type:
                    # æ·»åŠ å›¾åƒæè¿°æ–‡æœ¬
                    temp_message_content_list.append({
                        "type": "text",
                        "text": f"Here is the image you requested to see: '{file_path}'"
                    })
                    # æ·»åŠ å›¾åƒURL
                    temp_message_content_list.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{base64_image}",
                        }
                    })

                # å¤„ç†å®Œå›¾åƒä¸Šä¸‹æ–‡åï¼Œåˆ é™¤è¯¥æ¶ˆæ¯ï¼ˆé¿å…é‡å¤ä½¿ç”¨ï¼‰
                await self.client.table('messages').delete().eq('message_id', latest_image_context_msg.data[0]["message_id"]).execute()
                
            except Exception as e:
                logger.error(f"Error parsing image context: {e}")

        # å¦‚æœæœ‰ä¸´æ—¶æ¶ˆæ¯å†…å®¹ï¼Œè¿”å›æ ¼å¼åŒ–çš„æ¶ˆæ¯
        if temp_message_content_list:
            return {"role": "user", "content": temp_message_content_list}
        return None

class AgentRunner:

    def __init__(self, config: AgentConfig):
        self.config = config
    
    async def setup(self):
        try:
            if not self.config.trace:
                self.config.trace = langfuse.trace(name="run_agent", session_id=self.config.thread_id, metadata={"project_id": self.config.project_id})
                logger.info(f"Langfuse trace created successfully")
            else:
                logger.info(f"Using existing trace")
     
            # ä½¿ç”¨ Google ADK æ¡†æ¶æ‰¿æ¥æœåŠ¡
            self.thread_manager = ADKThreadManager(
                        trace=self.config.trace, 
                        is_agent_builder=self.config.is_agent_builder or False, 
                        target_agent_id=self.config.target_agent_id, 
                        agent_config=self.config.agent_config
                    )
            logger.info(f"ADKThreadManager created successfully")

            # åˆå§‹åŒ–æ•°æ®åº“å®¢æˆ·ç«¯
            self.client = await self.thread_manager.db.client
            logger.info(f"Database client initialized successfully")

            # è·å–è´¦æˆ·ID
            from utils.auth_utils import AuthUtils
            self.account_id = await AuthUtils.get_account_id_from_thread(self.client, self.config.thread_id)
            if not self.account_id: 
                raise ValueError("Could not determine account ID for thread")

            # è·å–é¡¹ç›®ä¿¡æ¯
            project = await self.client.table('projects').select('*').eq('project_id', self.config.project_id).execute()
            if not project.data or len(project.data) == 0:
                raise ValueError(f"Project {self.config.project_id} not found")

            project_data = project.data[0]
            sandbox_info = project_data.get('sandbox', {})

            # å¤„ç† sandbox_info å¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
            if isinstance(sandbox_info, str):
                try:
                    import json
                    sandbox_info = json.loads(sandbox_info)
                except (json.JSONDecodeError, TypeError):
                    sandbox_info = {}

            if not sandbox_info.get('id'):
                # æ²™ç®±æ˜¯æ‡’åŠ è½½çš„ï¼Œå½“éœ€è¦æ—¶åˆ›å»ºå’ŒæŒä¹…åŒ–æ²™ç®±å…ƒæ•°æ®
                # å¦‚æœæ²™ç®±ä¸å­˜åœ¨ï¼Œå·¥å…·ä¼šè°ƒç”¨ `_ensure_sandbox()` æ¥åˆ›å»ºå’ŒæŒä¹…åŒ–æ²™ç®±å…ƒæ•°æ®
                logger.info(f"No sandbox found for project {self.config.project_id}; will create lazily when needed")
            
        except Exception as setup_error:
            logger.error(f"Error details: {traceback.format_exc()}")
            raise setup_error
        
    async def setup_tools(self):
        tool_manager = ToolManager(self.thread_manager, self.config.project_id, self.config.thread_id)
        if self.config.agent_config and self.config.agent_config.get('is_fufanmanus_default', False):
            tool_manager.register_all_tools()
            logger.info("register all tools successï¼")

    
    def get_max_tokens(self) -> Optional[int]:
        if "sonnet" in self.config.model_name.lower():
            return 8192
        elif "gpt-4" in self.config.model_name.lower():
            return 4096
        elif "gemini-2.5-pro" in self.config.model_name.lower():
            return 64000
        elif "kimi-k2" in self.config.model_name.lower():
            return 8192
        return None
    
    
    async def run(self) -> AsyncGenerator[Dict[str, Any], None]:
        await self.setup()
        await self.setup_tools()

        # mcp_wrapper_instance = await self.setup_mcp_tools()
        
        # system_message = await PromptManager.build_system_prompt(
        #     self.config.model_name, self.config.agent_config, 
        #     self.config.is_agent_builder, self.config.thread_id, 
        #     mcp_wrapper_instance
        # )

        system_message = await PromptManager.build_system_prompt(
            self.config.model_name, self.config.agent_config, 
            self.config.is_agent_builder, self.config.thread_id, 
        )
        logger.info(f"system_message created successfully")

        # åˆå§‹åŒ–è¿­ä»£æ¬¡æ•°
        iteration_count = 0

        # åˆå§‹åŒ–ç»§ç»­æ‰§è¡Œæ ‡å¿—
        continue_execution = True

        # è·å–æœ€æ–°æ¶ˆæ¯ - ä»eventsè¡¨è·å–
        latest_user_message = await self.client.table('events').select('*').eq('session_id', self.config.thread_id).order('timestamp', desc=True).limit(10).execute()
        logger.info(f"Event table query result: {len(latest_user_message.data) if latest_user_message.data else 0}")

        # æå–ç”¨æˆ·è¯·æ±‚å†…å®¹
        user_request = None
        if latest_user_message.data and len(latest_user_message.data) > 0:
            logger.info(f"Latest 10 messages author list: {[msg.get('author') for msg in latest_user_message.data]}")
            
            # æ‰¾åˆ°æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
            for i, event in enumerate(latest_user_message.data):
                if event.get('author') == 'user':
                    content = event.get('content', {})
                    timestamp = event.get('timestamp')
                    logger.info(f"Found user message[{i}]: content={content}, timestamp={timestamp}")
                    
                    import json
                    # è§£æcontentå­—æ®µ
                    if isinstance(content, str):
                        try:
                            content = json.loads(content)
                        except json.JSONDecodeError:
                            content = {"content": content}
                    
                    # æå–ç”¨æˆ·è¯·æ±‚
                    if isinstance(content, dict):
                        user_request = content.get('content', '')
                        logger.info(f"Extracted user request: {user_request}")
                    break
            
            if self.config.trace and user_request:
                self.config.trace.update(input=user_request)

        message_manager = MessageManager(self.client, self.config.thread_id, self.config.model_name, self.config.trace)

        # è¿›å…¥å¾ªç¯æ‰§è¡Œ
        while continue_execution and iteration_count < self.config.max_iterations:
            iteration_count += 1          
            logger.info(f"Loopingï¼šcontinue_execution={continue_execution}, iteration_count={iteration_count}, max_iterations={self.config.max_iterations}")
            
            # can_run, message, subscription = await check_billing_status(self.client, self.account_id)
            # if not can_run:
            #     error_msg = f"Billing limit reached: {message}"
            #     yield {
            #         "type": "status",
            #         "status": "stopped",
            #         "message": error_msg
            #     }
            #     break

            temporary_message = await message_manager.build_temporary_message()
            logger.info(f"temporary_message created successfully: {temporary_message}")
            # max_tokens = self.get_max_tokens()
            
            generation = self.config.trace.generation(name="thread_manager.run_thread") if self.config.trace else None
            try:          
                # è·å–å¯ç”¨å‡½æ•°
                available_functions = self.thread_manager.tool_registry.get_available_functions()
                logger.info(f"Get available functions: {list(available_functions.keys())}")
                
                response = await self.thread_manager.run_thread( 
                        thread_id=self.config.thread_id,
                        system_prompt=system_message,
                        stream=self.config.stream,
                        llm_model=self.config.model_name,
                        llm_temperature=0,
                        # llm_max_tokens=max_tokens,
                        llm_max_tokens=1024,
                        tool_choice="auto",
                        available_functions = available_functions,
                        max_xml_tool_calls=0, # è¿™é‡Œä¸è®¾ç½®é™åˆ¶
                        temporary_message=temporary_message,
                        processor_config=ProcessorConfig(
                            xml_tool_calling=True,
                            native_tool_calling=False,
                            execute_tools=True,
                            execute_on_stream=True,
                            tool_execution_strategy="parallel",
                            xml_adding_strategy="user_message"
                        ),
                        native_max_auto_continues=self.config.native_max_auto_continues,
                        include_xml_examples=True,
                        enable_thinking=self.config.enable_thinking,
                        reasoning_effort=self.config.reasoning_effort,
                        enable_context_manager=self.config.enable_context_manager,
                        generation=generation
                    )
   
                if isinstance(response, dict) and "status" in response and response["status"] == "error":
                    yield response
                    break

                last_tool_call = None
                agent_should_terminate = False
                error_detected = False
                full_response = ""

                try:
                    if hasattr(response, '__aiter__') and not isinstance(response, dict):
                        async for chunk in response:
                            if isinstance(chunk, dict) and chunk.get('type') == 'status' and chunk.get('status') == 'error':
                                error_detected = True
                                yield chunk
                                continue
                            
                            if chunk.get('type') == 'status':
                                try:
                                    metadata = chunk.get('metadata', {})
                                    if isinstance(metadata, str):
                                        metadata = json.loads(metadata)
                                    
                                    if metadata.get('agent_should_terminate'):
                                        agent_should_terminate = True
                                        
                                        content = chunk.get('content', {})
                                        if isinstance(content, str):
                                            content = json.loads(content)
                                        
                                        if content.get('function_name'):
                                            last_tool_call = content['function_name']
                                        elif content.get('xml_tag_name'):
                                            last_tool_call = content['xml_tag_name']
                                            
                                except Exception:
                                    pass
                            
                            if chunk.get('type') == 'assistant' and 'content' in chunk:
                                try:
                                    content = chunk.get('content', '{}')
                                    if isinstance(content, str):
                                        assistant_content_json = json.loads(content)
                                    else:
                                        assistant_content_json = content

                                    assistant_text = assistant_content_json.get('content', '')
                                    full_response += assistant_text
                                    if isinstance(assistant_text, str):
                                        if '</ask>' in assistant_text or '</complete>' in assistant_text or '</web-browser-takeover>' in assistant_text:
                                            if '</ask>' in assistant_text:
                                                xml_tool = 'ask'
                                            elif '</complete>' in assistant_text:
                                                xml_tool = 'complete'
                                            elif '</web-browser-takeover>' in assistant_text:
                                                xml_tool = 'web-browser-takeover'

                                            last_tool_call = xml_tool
                                
                                except json.JSONDecodeError:
                                    pass
                                except Exception:
                                    pass

                            yield chunk
                    else:
                        error_detected = True

                    if error_detected:
                        if generation:
                            generation.end(output=full_response, status_message="error_detected", level="ERROR")
                        break
                        
                    if agent_should_terminate or last_tool_call in ['ask', 'complete', 'web-browser-takeover']:
                        if generation:
                            generation.end(output=full_response, status_message="agent_stopped")
                        continue_execution = False
                    else:
                        # âœ… æ­£å¸¸å®Œæˆä¸€è½®å¯¹è¯åï¼Œä¹Ÿè¦ç»ˆæ­¢å¾ªç¯ï¼ˆé™¤ééœ€è¦ç»§ç»­æ‰§è¡Œä»»åŠ¡ï¼‰
                        continue_execution = False

                except Exception as e:
                    error_msg = f"Error during response streaming: {str(e)}"
                    if generation:
                        generation.end(output=full_response, status_message=error_msg, level="ERROR")
                    yield {
                        "type": "status",
                        "status": "error", 
                        "message": error_msg
                    }
                    break
                     
            except Exception as e:
                error_msg = f"Error running thread: {str(e)}"
                yield {
                    "type": "status",
                    "status": "error", 
                    "message": error_msg
                }
                break
            
            if generation:
                generation.end(output=full_response)

        asyncio.create_task(asyncio.to_thread(lambda: langfuse.flush()))
        #         if isinstance(response, dict) and "status" in response and response["status"] == "error":
        #             yield response
        #             break

        #         last_tool_call = None
        #         agent_should_terminate = False
        #         error_detected = False
        #         full_response = ""
        #         final_response_text = None  # âœ… ç”¨äºå­˜å‚¨is_final_responseçš„å†…å®¹
        #         adk_call_completed = False  # âœ… æ ‡è®°å•æ¬¡ADKè°ƒç”¨æ˜¯å¦å®Œæˆ

        #         try:
        #             all_chunk = []
        #             if hasattr(response, '__aiter__') and not isinstance(response, dict):
        #                 async for chunk in response:
        #                     print(f"current chunk: {chunk}")
        #                     # âœ… åŸºäºå®é™…äº‹ä»¶æ ¼å¼çš„å¤„ç†é€»è¾‘
        #                     if isinstance(chunk, dict):
        #                         chunk_type = chunk.get('type')
        #                         chunk_content = chunk.get('content', '{}')
        #                         chunk_metadata = chunk.get('metadata', '{}')
                                
        #                         # è§£æJSONå­—ç¬¦ä¸²
        #                         try:
        #                             if isinstance(chunk_content, str):
        #                                 content_data = json.loads(chunk_content)
        #                             else:
        #                                 content_data = chunk_content
                                        
        #                             if isinstance(chunk_metadata, str):
        #                                 metadata_data = json.loads(chunk_metadata)
        #                             else:
        #                                 metadata_data = chunk_metadata
        #                         except json.JSONDecodeError:
        #                             content_data = {}
        #                             metadata_data = {}
                                
        #                         # âœ… æ£€æŸ¥assistantæ¶ˆæ¯çš„å®ŒæˆçŠ¶æ€
        #                         if chunk_type == 'assistant' and metadata_data.get('stream_status') == 'complete':
        #                             if content_data.get('content'):
        #                                 final_response_text = content_data['content']
        #                                 logger.info(f"ğŸ¯ æ£€æµ‹åˆ°å®Œæ•´assistantå›å¤: {final_response_text[:100]}...")
                                
        #                         # âœ… æ£€æŸ¥finishçŠ¶æ€ï¼ˆç±»ä¼¼is_final_responseï¼‰
        #                         elif chunk_type == 'status' and content_data.get('status_type') == 'finish':
        #                             if content_data.get('finish_reason') == 'final':
        #                                 logger.info(f"ğŸ æ£€æµ‹åˆ°final finishçŠ¶æ€")
        #                                 # è¿™è¡¨ç¤ºå½“å‰å›åˆçš„æœ€ç»ˆå“åº”
                                
        #                         # âœ… æ£€æŸ¥thread_run_endï¼ˆè°ƒç”¨å®Œå…¨ç»“æŸï¼‰
        #                         elif chunk_type == 'status' and content_data.get('status_type') == 'thread_run_end':
        #                             logger.info(f"ğŸ¯ æ£€æµ‹åˆ°thread_run_endï¼ŒADKè°ƒç”¨å®Œå…¨ç»“æŸ")
        #                             adk_call_completed = True
                                
        #                         # âœ… æ£€æŸ¥é”™è¯¯çŠ¶æ€
        #                         elif chunk_type == 'status' and chunk.get('status') == 'error':
        #                             error_detected = True
        #                             yield chunk
        #                             continue
                        
        #                         # âœ… æ£€æŸ¥å·¥å…·è°ƒç”¨å’Œç»ˆæ­¢æ¡ä»¶ (å¦‚æœè¿˜æœ‰å…¶ä»–é€»è¾‘éœ€è¦)
        #                         if chunk_type == 'assistant':
        #                             # ğŸ”§ ä»ADKæ ¼å¼ä¸­æ­£ç¡®æå–æ–‡æœ¬
        #                             assistant_text = ""
        #                             if content_data.get('content'):
        #                                 # æ—§æ ¼å¼ï¼š{"content": "text"}
        #                                 assistant_text = str(content_data['content'])
        #                             elif content_data.get('parts'):
        #                                 # ADKæ ¼å¼ï¼š{"role": "model", "parts": [{"text": "..."}]}
        #                                 for part in content_data['parts']:
        #                                     if isinstance(part, dict) and 'text' in part:
        #                                         # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨å¤„ç†part['text']ï¼Œé˜²æ­¢listç±»å‹å¯¼è‡´æ‹¼æ¥é”™è¯¯
        #                                         part_text = part['text']
        #                                         if isinstance(part_text, list):
        #                                             part_text = ''.join(str(item) for item in part_text)
        #                                         elif not isinstance(part_text, str):
        #                                             part_text = str(part_text)
        #                                         assistant_text += part_text
                                    
        #                             if assistant_text:
        #                                 # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿full_responseæ‹¼æ¥çš„ç±»å‹å®‰å…¨
        #                                 if not isinstance(full_response, str):
        #                                     full_response = str(full_response)
        #                                 if not isinstance(assistant_text, str):
        #                                     assistant_text = str(assistant_text)
        #                                 full_response += assistant_text
                                    
        #                             # æ£€æŸ¥XMLå·¥å…·è°ƒç”¨
        #                             if isinstance(assistant_text, str):
        #                                 if '</ask>' in assistant_text:
        #                                     last_tool_call = 'ask'
        #                                     agent_should_terminate = True
        #                                 elif '</complete>' in assistant_text:
        #                                     last_tool_call = 'complete' 
        #                                     agent_should_terminate = True
        #                                 elif '</web-browser-takeover>' in assistant_text:
        #                                     last_tool_call = 'web-browser-takeover'
        #                                     agent_should_terminate = True

        #                     yield chunk
                        
        #                 # âœ… å½“async forå¾ªç¯ç»“æŸæ—¶ï¼Œè¯´æ˜äº‹ä»¶æµè€—å°½
        #                 if not adk_call_completed:
        #                     adk_call_completed = True
        #                     logger.info(f"ğŸ ADKäº‹ä»¶æµè€—å°½ï¼Œå•æ¬¡è°ƒç”¨å®Œæˆ")

                      
        #             else:
        #                 error_detected = True
        #             logger.info(f"123all_chunk: {all_chunk}")    
        #         except Exception as stream_error:
        #             error_msg = f"Error during response streaming: {str(stream_error)}"
        #             logger.error(error_msg)
        #             if generation:
        #                 generation.end(output=full_response, status_message=error_msg, level="ERROR")
        #             yield {
        #                 "type": "status",
        #                 "status": "error",
        #                 "message": error_msg
        #             }
        #             break
                    
        #     except Exception as run_error:
        #         error_msg = f"Error running thread: {str(run_error)}"
        #         logger.error(error_msg)
        #         yield {
        #             "type": "status",
        #             "status": "error",
        #             "message": error_msg
        #         }
        #         break
            
        #     # âœ… å¤–å±‚å¾ªç¯ç»ˆæ­¢åˆ¤æ–­ï¼ˆåŸºäºå®é™…äº‹ä»¶ï¼‰
        #     if error_detected:
        #         logger.info(f"ğŸš¨ æ£€æµ‹åˆ°é”™è¯¯ï¼Œç»ˆæ­¢æ‰§è¡Œ")
        #         if generation:
        #             generation.end(output=full_response, status_message="error_detected", level="ERROR")
        #         break
                
        #     # âœ… åŸºäºå®é™…ADKäº‹ä»¶çš„ç»ˆæ­¢åˆ¤æ–­
        #     if agent_should_terminate or last_tool_call in ['ask', 'complete', 'web-browser-takeover']:
        #         logger.info(f"ğŸ›‘ Agentæ˜ç¡®ç»ˆæ­¢: agent_should_terminate={agent_should_terminate}, last_tool_call={last_tool_call}")
        #         if generation:
        #             generation.end(output=full_response, status_message="agent_stopped")
        #         continue_execution = False
        #         logger.info(f"ğŸ›‘ è®¾ç½®continue_execution=Falseï¼Œåº”è¯¥é€€å‡ºå¾ªç¯")
                
        #     elif adk_call_completed:
        #         # âœ… ADKè°ƒç”¨å®Œæˆåï¼Œç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£è®©Agentæ‰§è¡Œæ›´å¤šä»»åŠ¡
        #         logger.info(f"âœ… ADKè°ƒç”¨å®Œæˆï¼Œç»§ç»­æ‰§è¡Œæ›´å¤šä»»åŠ¡ (iteration {iteration_count}/{self.config.max_iterations})")
        #         if final_response_text:
        #             logger.info(f"ğŸ“ æœ¬è½®å“åº”é¢„è§ˆ: {final_response_text[:200]}...")
        #         # continue_executionä¿æŒTrueï¼Œè®©Agentç»§ç»­æ‰§è¡Œä»»åŠ¡
                
        #     else:
        #         # âœ… å…¶ä»–æƒ…å†µ
        #         logger.info(f"â“ æœªæ˜ç¡®çš„ADKçŠ¶æ€ (completed={adk_call_completed}, final_text={bool(final_response_text)})ï¼Œç»§ç»­å°è¯•")
            
        #     if generation:
        #         generation.end(output=full_response)

        # # ğŸ” å¾ªç¯ç»“æŸæ—¥å¿—
        # logger.info(f"ğŸ Agentæ‰§è¡Œå¾ªç¯ç»“æŸ: continue_execution={continue_execution}, iteration_count={iteration_count}")
        # logger.info(f"ğŸ æœ€ç»ˆçŠ¶æ€: max_iterations={self.config.max_iterations}")
        # #                     # âœ… å®˜æ–¹æ¨èï¼šç”¨is_final_response()è·å–æœ€ç»ˆå¯å±•ç¤ºæ–‡æœ¬
        # #                     if hasattr(chunk, 'is_final_response') and chunk.is_final_response():
        # #                         if hasattr(chunk, 'content') and chunk.content and hasattr(chunk.content, 'parts') and chunk.content.parts:
        # #                             final_response_text = chunk.content.parts[0].text
        # #                             logger.info(f"ğŸ¯ æ£€æµ‹åˆ°final_response: {final_response_text[:100]}...")
                            
        # #                     if isinstance(chunk, dict) and chunk.get('type') == 'status' and chunk.get('status') == 'error':
        # #                         error_detected = True
        # #                         yield chunk
        # #                         continue
                            
        # #                     if chunk.get('type') == 'status':
        # #                         try:
        # #                             metadata = chunk.get('metadata', {})
        # #                             if isinstance(metadata, str):
        # #                                 metadata = json.loads(metadata)
                                    
        # #                             if metadata.get('agent_should_terminate'):
        # #                                 agent_should_terminate = True
                                        
        # #                                 content = chunk.get('content', {})
        # #                                 if isinstance(content, str):
        # #                                     content = json.loads(content)
                                        
        # #                                 if content.get('function_name'):
        # #                                     last_tool_call = content['function_name']
        # #                                 elif content.get('xml_tag_name'):
        # #                                     last_tool_call = content['xml_tag_name']
                                            
        # #                         except Exception:
        # #                             pass
                            
        # #                     if chunk.get('type') == 'assistant' and 'content' in chunk:
        # #                         try:
        # #                             content = chunk.get('content', '{}')
        # #                             if isinstance(content, str):
        # #                                 assistant_content_json = json.loads(content)
        # #                             else:
        # #                                 assistant_content_json = content

        # #                             assistant_text = assistant_content_json.get('content', '')
        # #                             full_response += assistant_text
        # #                             if isinstance(assistant_text, str):
        # #                                 if '</ask>' in assistant_text or '</complete>' in assistant_text or '</web-browser-takeover>' in assistant_text:
        # #                                    if '</ask>' in assistant_text:
        # #                                        xml_tool = 'ask'
        # #                                    elif '</complete>' in assistant_text:
        # #                                        xml_tool = 'complete'
        # #                                    elif '</web-browser-takeover>' in assistant_text:
        # #                                        xml_tool = 'web-browser-takeover'

        # #                                    last_tool_call = xml_tool
                                
        # #                         except json.JSONDecodeError:
        # #                             pass
        # #                         except Exception:
        # #                             pass

        # #                     yield chunk
                        
        # #                 # âœ… å½“async forå¾ªç¯ç»“æŸæ—¶ï¼Œè¯´æ˜è¿™æ¬¡ADKè°ƒç”¨çš„äº‹ä»¶æµå·²è€—å°½
        # #                 adk_call_completed = True
        # #                 logger.info(f"ğŸ ADKäº‹ä»¶æµè€—å°½ï¼Œå•æ¬¡è°ƒç”¨å®Œæˆ")
                        
        # #             else:
        # #                 error_detected = True

        # #             if error_detected:
        # #                 logger.info(f"ğŸš¨ æ£€æµ‹åˆ°é”™è¯¯ï¼Œç»ˆæ­¢æ‰§è¡Œ")
        # #                 if generation:
        # #                     generation.end(output=full_response, status_message="error_detected", level="ERROR")
        # #                 break
                        
        # #             # âœ… åŸºäºå®˜æ–¹å»ºè®®çš„å¤–å±‚å¾ªç¯ç»ˆæ­¢åˆ¤æ–­
        # #             if agent_should_terminate or last_tool_call in ['ask', 'complete', 'web-browser-takeover']:
        # #                 logger.info(f"ğŸ›‘ Agentæ˜ç¡®ç»ˆæ­¢: agent_should_terminate={agent_should_terminate}, last_tool_call={last_tool_call}")
        # #                 if generation:
        # #                     generation.end(output=full_response, status_message="agent_stopped")
        # #                 continue_execution = False
        # #                 logger.info(f"ğŸ›‘ è®¾ç½®continue_execution=Falseï¼Œåº”è¯¥é€€å‡ºå¾ªç¯")
        # #             elif adk_call_completed and final_response_text:
        # #                 # âœ… ADKè°ƒç”¨å®Œæˆä¸”æœ‰æœ€ç»ˆå“åº”æ–‡æœ¬ï¼Œé€šå¸¸è¡¨ç¤ºä¸€è½®å®Œæ•´å¯¹è¯ç»“æŸ
        # #                 logger.info(f"âœ… ADKè°ƒç”¨å®Œæˆä¸”æœ‰æœ€ç»ˆå“åº”ï¼Œé»˜è®¤ç»ˆæ­¢å¤–å±‚å¾ªç¯")
        # #                 logger.info(f"ğŸ“ æœ€ç»ˆå“åº”é¢„è§ˆ: {final_response_text[:200]}...")
        # #                 continue_execution = False
        # #             elif adk_call_completed and not final_response_text:
        # #                 # âœ… ADKè°ƒç”¨å®Œæˆä½†æ²¡æœ‰æœ€ç»ˆå“åº”æ–‡æœ¬ï¼Œå¯èƒ½éœ€è¦ç»§ç»­
        # #                 logger.info(f"âš ï¸ ADKè°ƒç”¨å®Œæˆä½†æ— æœ€ç»ˆå“åº”æ–‡æœ¬ï¼Œç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£")
        # #                 # continue_executionä¿æŒTrueï¼Œç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£
        # #             else:
        # #                 # âœ… å…¶ä»–æƒ…å†µï¼Œå¯èƒ½æ˜¯ADKå†…éƒ¨é”™è¯¯æˆ–å¼‚å¸¸çŠ¶æ€
        # #                 logger.info(f"â“ æœªæ˜ç¡®çš„ADKçŠ¶æ€ (completed={adk_call_completed}, final_text={bool(final_response_text)})ï¼Œç»§ç»­å°è¯•")

        # #         except Exception as e:
        # #             error_msg = f"Error during response streaming: {str(e)}"
        # #             if generation:
        # #                 generation.end(output=full_response, status_message=error_msg, level="ERROR")
        # #             yield {
        # #                 "type": "status",
        # #                 "status": "error",
        # #                 "message": error_msg
        # #             }
        # #             break
                    
        # #     except Exception as e:
        # #         error_msg = f"Error running thread: {str(e)}"
        # #         yield {
        # #             "type": "status",
        # #             "status": "error",
        # #             "message": error_msg
        # #         }
        # #         break
            
        # #     if generation:
        # #         generation.end(output=full_response)

        # # # ğŸ” å¾ªç¯ç»“æŸæ—¥å¿—
        # # logger.info(f"ğŸ Agentæ‰§è¡Œå¾ªç¯ç»“æŸ: continue_execution={continue_execution}, iteration_count={iteration_count}")
        # # logger.info(f"ğŸ æœ€ç»ˆçŠ¶æ€: max_iterations={self.config.max_iterations}")

        # asyncio.create_task(asyncio.to_thread(lambda: langfuse.flush()))


    # async def run(self) -> AsyncGenerator[Dict[str, Any], None]:
        # """è¿è¡ŒAgentï¼Œæ”¯æŒADKå’ŒThreadManagerä¸¤ç§æ¨¡å¼"""
        # print(f"ğŸš€ ===== AgentRunner.run()å¼€å§‹æ‰§è¡Œ =====")
        # try:
        #     # æ£€æŸ¥ä½¿ç”¨å“ªç§æ¨¡å¼
        #     if self.adk_runner and self.adk_session:
        #         print(f"  ğŸ”„ ä½¿ç”¨ADKæ¨¡å¼æ‰§è¡Œ...")
        #         async for event in self._run_with_adk():
        #             yield event
        #     elif self.thread_manager:
        #         print(f"  ğŸ”„ ä½¿ç”¨ThreadManageræ¨¡å¼æ‰§è¡Œ...")
        #         async for event in self._run_with_thread_manager():
        #             yield event
        #     else:
        #         raise RuntimeError("Neither ADK Runner nor ThreadManager initialized. Call setup() first.")
            
        #     print(f"  âœ… AgentRunner.run()æ‰§è¡Œå®Œæˆ")
            
        # except Exception as run_error:
        #     print(f"  âŒ AgentRunner.run()æ‰§è¡Œå¤±è´¥: {run_error}")
        #     print(f"  ğŸ“‹ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        #     # è¿”å›é”™è¯¯äº‹ä»¶
        #     yield {
        #         "type": "error",
        #         "content": f"Agent execution failed: {str(run_error)}",
        #         "metadata": {"error": str(run_error)}
        #     }
    
    async def _run_with_adk(self) -> AsyncGenerator[Dict[str, Any], None]:
        """ä½¿ç”¨ADK Runneræ‰§è¡Œ"""
        try:
            print(f"  ğŸ“ å‡†å¤‡ç”¨æˆ·è¾“å…¥...")
            # å‡†å¤‡ç”¨æˆ·è¾“å…¥å†…å®¹
            user_content = types.Content(
                role='user',
                parts=[types.Part.from_text(text=self.config.user_message or "Hello")]
            )
            print(f"  âœ… ç”¨æˆ·è¾“å…¥å‡†å¤‡å®Œæˆ")
            
            print(f"  ğŸ”„ å¼€å§‹ADK Runneræ‰§è¡Œ...")
            # ä½¿ç”¨ADK Runneræ‰§è¡Œ
            async for event in self.adk_runner.run_async(
                user_id=self.adk_session.user_id,
                content=user_content,
                session_id=self.adk_session.id
            ):
                print(f"  ğŸ“¨ æ”¶åˆ°ADKäº‹ä»¶: {event.type}")
                
                # å°†ADKäº‹ä»¶è½¬æ¢ä¸ºä½ çš„æ ¼å¼
                converted_event = self._convert_adk_event_to_format(event)
                if converted_event:
                    yield converted_event
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if event.type == "assistant_response_end":
                    print(f"  âœ… ADKæ‰§è¡Œå®Œæˆ")
                    break
                    
        except Exception as adk_error:
            print(f"  âŒ ADKæ‰§è¡Œå¤±è´¥: {adk_error}")
            yield {
                "type": "error",
                "content": f"ADK execution failed: {str(adk_error)}",
                "metadata": {"error": str(adk_error)}
            }
    
    async def _run_with_thread_manager(self) -> AsyncGenerator[Dict[str, Any], None]:
        """ä½¿ç”¨ThreadManageræ‰§è¡Œï¼ˆå›é€€æ¨¡å¼ï¼‰"""
        try:
            print(f"  ğŸ“ å‡†å¤‡ThreadManageræ‰§è¡Œ...")
            
            # æ„å»ºä¸´æ—¶æ¶ˆæ¯
            temporary_message = None
            if self.client:
                try:
                    message_manager = MessageManager(
                        self.client, 
                        self.config.thread_id, 
                        self.config.model_name, 
                        self.config.trace
                    )
                    temporary_message = await message_manager.build_temporary_message()
                    if temporary_message:
                        print(f"  âœ… ä¸´æ—¶æ¶ˆæ¯æ„å»ºæˆåŠŸ")
                    else:
                        print(f"  â„¹ï¸ æ²¡æœ‰ä¸´æ—¶æ¶ˆæ¯")
                except Exception as msg_error:
                    print(f"  âš ï¸ æ„å»ºä¸´æ—¶æ¶ˆæ¯å¤±è´¥: {msg_error}")
                    temporary_message = None
            
            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = PromptManager.build_system_prompt(
                model_name=self.config.model_name,
                agent_config=self.config.agent_config,
                is_agent_builder=self.config.is_agent_builder or False,
                thread_id=self.config.thread_id
            )
            
            # ä½¿ç”¨åŸæœ‰çš„ThreadManageré€»è¾‘
            response = await self.thread_manager.run_thread(
                thread_id=self.config.thread_id,
                system_prompt=system_prompt,
                stream=self.config.stream,
                temporary_message=temporary_message,
                llm_model=self.config.model_name,
                enable_thinking=self.config.enable_thinking,
                reasoning_effort=self.config.reasoning_effort,
                enable_context_manager=self.config.enable_context_manager
            )
            
            # å¤„ç†å“åº”
            if response:
                yield {
                    "type": "assistant",
                    "content": {"role": "assistant", "content": str(response)},
                    "metadata": {"thread_run_id": self.config.agent_run_id}
                }
            
            print(f"  âœ… ThreadManageræ‰§è¡Œå®Œæˆ")
            
        except Exception as tm_error:
            print(f"  âŒ ThreadManageræ‰§è¡Œå¤±è´¥: {tm_error}")
            yield {
                "type": "error",
                "content": f"ThreadManager execution failed: {str(tm_error)}",
                "metadata": {"error": str(tm_error)}
            }
    
    def _convert_adk_event_to_format(self, adk_event) -> Optional[Dict[str, Any]]:
        """å°†ADKäº‹ä»¶è½¬æ¢ä¸ºä½ çš„æ ¼å¼"""
        try:
            if adk_event.type == "assistant_response_start":
                return {
                    "type": "status",
                    "content": {"status_type": "assistant_response_start"},
                    "metadata": {"thread_run_id": self.config.agent_run_id}
                }
            
            elif adk_event.type == "assistant_response":
                # å¤„ç†åŠ©æ‰‹å“åº”
                content = adk_event.content
                if content and hasattr(content, 'parts'):
                    text_content = ""
                    for part in content.parts:
                        if hasattr(part, 'text'):
                            # ğŸ”§ ç¡®ä¿ç±»å‹å®‰å…¨ï¼Œé˜²æ­¢å­—ç¬¦ä¸²æ‹¼æ¥é”™è¯¯
                            part_text = part.text
                            if isinstance(part_text, list):
                                part_text = ''.join(str(item) for item in part_text)
                            elif not isinstance(part_text, str):
                                part_text = str(part_text)
                            text_content += part_text
                    
                    return {
                        "type": "assistant",
                        "content": {"role": "assistant", "content": text_content},
                        "metadata": {"stream_status": "chunk", "thread_run_id": self.config.agent_run_id}
                    }
            
            elif adk_event.type == "tool_started":
                # å¤„ç†å·¥å…·è°ƒç”¨
                return {
                    "type": "status",
                    "content": {
                        "role": "assistant",
                        "status_type": "tool_started",
                        "tool_name": adk_event.tool_name,
                        "tool_args": adk_event.tool_args
                    },
                    "metadata": {"thread_run_id": self.config.agent_run_id}
                }
            
            elif adk_event.type == "tool_result":
                # å¤„ç†å·¥å…·ç»“æœ
                return {
                    "type": "tool",
                    "content": {
                        "role": "tool",
                        "tool_name": adk_event.tool_name,
                        "result": adk_event.result
                    },
                    "metadata": {"thread_run_id": self.config.agent_run_id}
                }
            
            elif adk_event.type == "assistant_response_end":
                # å¤„ç†å“åº”ç»“æŸ
                return {
                    "type": "status",
                    "content": {"status_type": "assistant_response_end"},
                    "metadata": {"thread_run_id": self.config.agent_run_id}
                }
            
            return None
            
        except Exception as convert_error:
            print(f"  âš ï¸ äº‹ä»¶è½¬æ¢å¤±è´¥: {convert_error}")
            return None

from agentpress.adk_thread_manager import ADKThreadManager
from typing import  Union


async def run_agent(
    thread_id: str,
    project_id: str,
    stream: bool,
    # thread_manager: Optional[Union[ThreadManager, ADKThreadManager]] = None,  
    native_max_auto_continues: int = 0,
    max_iterations: int = 100,
    model_name: str = "deepseek/deepseek-chat",
    enable_thinking: Optional[bool] = False,
    reasoning_effort: Optional[str] = 'low',
    enable_context_manager: bool = True,
    agent_config: Optional[dict] = None,    
    trace: Optional[StatefulTraceClient] = None, # type: ignore
    is_agent_builder: Optional[bool] = False,
    target_agent_id: Optional[str] = None,
):
    logger.info(f"Using thread_id: {thread_id}")
    logger.info(f"Using project_id: {project_id}")
    logger.info(f"Using stream: {stream}")
    logger.info(f"Using model_name: {model_name}")
    if agent_config:
        logger.info(f"Using agent_config: {agent_config.get('name', 'Unknown')}")
    else:
        logger.info(f"Using agent_config: None")

    effective_model = model_name
    if model_name == "deepseek/deepseek-chat" and agent_config and agent_config.get('model'):
        effective_model = agent_config['model']
        logger.info(f"Using model from agent config: {effective_model}")
    elif model_name != "deepseek/deepseek-chat":
        logger.info(f"Using user-selected model: {effective_model}")
    else:
        logger.info(f"Using default model: {effective_model}")
    
    logger.info(f"Creating AgentConfig")

    config = AgentConfig(
        thread_id=thread_id,
        project_id=project_id,
        stream=stream,
        native_max_auto_continues=native_max_auto_continues, # æ§åˆ¶ AI Agent è‡ªåŠ¨ç»§ç»­å¯¹è¯çš„æœ€å¤§æ¬¡æ•°
        max_iterations=max_iterations, # Agent æœ€å¤§è¿­ä»£æ¬¡æ•°
        model_name=effective_model,
        enable_thinking=enable_thinking,  # æ˜¯å¦å¯ç”¨æ€è€ƒ
        reasoning_effort=reasoning_effort,  # æ€è€ƒåŠ›åº¦
        enable_context_manager=enable_context_manager,
        agent_config=agent_config,  # Agent é…ç½®
        trace=trace,
        is_agent_builder=is_agent_builder,  # æ˜¯å¦æ˜¯ Agent æ„å»ºå™¨
        target_agent_id=target_agent_id,  # ç›®æ ‡ Agent ID
    )

    # åˆ›å»º Runner 
    runner = AgentRunner(config)
    logger.info(f"AgentRunner created successfully: {runner}")
    
    try:
        logger.info(f"Starting to run runner.run()")
        async for chunk in runner.run():
            yield chunk
    except Exception as run_error:
        logger.error(f"runner.run() failed: {run_error}")
        logger.error(f"Error details: {traceback.format_exc()}")
        raise run_error