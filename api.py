from dotenv import load_dotenv # type: ignore
load_dotenv(override=True)

# è®¾ç½®æ—¥å¿—çº§åˆ«
import os
if not os.getenv("LOGGING_LEVEL"):
    os.environ["LOGGING_LEVEL"] = "INFO"
if not os.getenv("ENV_MODE"):
    os.environ["ENV_MODE"] = "LOCAL"

import asyncio
import time
import uuid
import sys

from fastapi import FastAPI, Request, HTTPException, Response, Depends, APIRouter # type: ignore
from utils.logger import logger, structlog
from datetime import datetime, timezone

from fastapi.middleware.cors import CORSMiddleware # type: ignore
# from fastapi.responses import JSONResponse, StreamingResponse
# from services import redis
# import sentry
from contextlib import asynccontextmanager
from services.postgresql import DBConnection
from utils.config import config, EnvMode
from collections import OrderedDict
# from pydantic import BaseModel
from flags import api as feature_flags_api
from agent import api as agent_api
from sandbox import api as sandbox_api
# from services import transcription as transcription_api
# from services import api_keys_api
from utils.simple_auth_middleware import get_current_user_id_from_jwt
# å¼ºåˆ¶ asyncio ä½¿ç”¨ Proactor äº‹ä»¶å¾ªç¯ï¼Œä»¥ç¡®ä¿å¼‚æ­¥ I/O çš„å…¼å®¹æ€§å’Œç¨³å®šæ€§ã€‚
if sys.platform == "win32":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# åˆå§‹åŒ–ç®¡ç†å™¨
db = DBConnection()
instance_id = "single"

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info(f"Starting up FastAPI application with instance ID: {instance_id} in {config.ENV_MODE.value} mode")
    try:
        # åˆå§‹åŒ–PostgreSQLæ•°æ®åº“è¿æ¥
        await db.initialize()
        logger.info("PostgreSQL database connection initialized successfully")
          
        # åˆå§‹åŒ–Redisè¿æ¥
        from services import redis
        try:
            await redis.initialize_async()
            logger.info("Redis connection initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Redis connection: {e}")

        # åˆå§‹åŒ–Agent
        agent_api.initialize(
            db,
            instance_id
        )

        # sandbox_api.initialize(db)
        
        # åˆå§‹åŒ–triggers API
        # è§¦å‘å™¨ç»„ä»¶ï¼Œç”¨äºè§¦å‘å·¥ä½œæµæ‰§è¡Œï¼ˆåŸºäºADKå¯ä»¥çœç•¥å¤§éƒ¨åˆ†çš„è§¦å‘å™¨å·¥ä½œæµï¼‰
        try:
            triggers_api.initialize(db)
            logger.info("Triggers API initialized successfully")
        except Exception as e:
            logger.warning(f"Triggers API initialization skipped: {e}")
        
        yield
        
        # æ¸…ç†Agentèµ„æº
        logger.info("Cleaning up agent resources")
        await agent_api.cleanup()
        
        # æ¸…ç†Redisè¿æ¥
        try:
            logger.info("Closing Redis connection")
            await redis.close()
            logger.info("Redis connection closed successfully")
        except Exception as e:
            logger.error(f"Error closing Redis connection: {e}")
        
        # æ¸…ç†æ•°æ®åº“è¿æ¥
        logger.info("Closing PostgreSQL database connection")
        await db.disconnect()
    except Exception as e:
        logger.error(f"Error during application startup: {e}")
        raise

app = FastAPI(lifespan=lifespan)


@app.middleware("http")
async def log_requests_middleware(request: Request, call_next):
    structlog.contextvars.clear_contextvars()
    request_id = str(uuid.uuid4())
    start_time = time.time()
    client_ip = request.client.host if request.client else "unknown"
    method = request.method
    path = request.url.path
    query_params = str(request.query_params)

    structlog.contextvars.bind_contextvars(
        request_id=request_id,
        client_ip=client_ip,
        method=method,
        path=path,
        query_params=query_params
    )

    # è®°å½•è¯·æ±‚
    logger.info(f"Request started: {method} {path} from {client_ip} | Query: {query_params}")
    
    try:
        response = await call_next(request)
        process_time = time.time() - start_time
        logger.debug(f"Request completed: {method} {path} | Status: {response.status_code} | Time: {process_time:.2f}s")
        return response
    except Exception as e:
        process_time = time.time() - start_time
        logger.error(f"Request failed: {method} {path} | Error: {str(e)} | Time: {process_time:.2f}s")
        raise

# å®šä¹‰å…è®¸çš„æº
allowed_origins = ["https://www.example.com", "https://example.com"]  # å¦‚æœæœ‰å¤šä¸ªæºï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
allow_origin_regex = None

# æ·»åŠ æœ¬åœ°å¼€å‘ç¯å¢ƒæº
if config.ENV_MODE == EnvMode.LOCAL:
    allowed_origins.append("http://localhost:3000")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"] if config.ENV_MODE == EnvMode.LOCAL else ["*"],
    allow_credentials=True,  # å…è®¸è®¤è¯å‡­æ®
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH"],  # æ˜¾å¼æŒ‡å®šæ–¹æ³•
    allow_headers=["Authorization", "Content-Type", "Accept", "Origin", "X-Requested-With"],  # æ˜¾å¼æŒ‡å®šå¤´éƒ¨
)

# åˆ›å»ºä¸»APIè·¯ç”±
api_router = APIRouter()

# æ·»åŠ é€šç”¨çš„OPTIONSå¤„ç†å™¨
@app.options("/{path:path}")
async def options_handler(path: str):
    """Handle OPTIONS preflight requests"""
    return {"message": "OK"}

# åŒ…å«è®¤è¯è·¯ç”±
from auth.api import router as auth_router

# ç”¨æˆ·è®¤è¯ç®¡ç†æ¨¡å—
api_router.include_router(auth_router)

# Include feature flags router
api_router.include_router(feature_flags_api.router)

# Include all API routers without individual prefixes
api_router.include_router(agent_api.router)

# Include agent versioning router
from agent.versioning.api import router as versioning_router
api_router.include_router(versioning_router)  
api_router.include_router(sandbox_api.router)

from triggers import api as triggers_api
api_router.include_router(triggers_api.router)

# api_router.include_router(api_keys_api.router)

# from mcp_module import api as mcp_api
# from credentials import api as credentials_api
# from templates import api as template_api

# api_router.include_router(mcp_api.router)
# api_router.include_router(credentials_api.router, prefix="/secure-mcp")
# api_router.include_router(template_api.router, prefix="/templates")

# api_router.include_router(transcription_api.router)
# api_router.include_router(email_api.router)

# from knowledge_base import api as knowledge_base_api
# api_router.include_router(knowledge_base_api.router)

# 

# from pipedream import api as pipedream_api
# api_router.include_router(pipedream_api.router)

# # MFA functionality moved to frontend


# from admin import api as admin_api
# api_router.include_router(admin_api.router)

# from composio_integration import api as composio_api
# api_router.include_router(composio_api.router)

@api_router.get("/sidebar/projects")
async def get_projects(user_id: str = Depends(get_current_user_id_from_jwt)):
    """get projects for sidebar"""
    try:
        logger.info(f"Getting projects for user: {user_id}")
        
        # è·å–æ•°æ®åº“å®¢æˆ·ç«¯
        client = await db.client
      
        # æŸ¥è¯¢ç”¨æˆ·çš„é¡¹ç›®åˆ—è¡¨
        logger.info(f"Querying projects table for account_id: {user_id}")
        result = await client.table("projects").select("*").eq("account_id", user_id).order("created_at", desc=True).execute()
        
        if hasattr(result, 'data'):
            logger.info(f"Projects result.data type: {type(result.data)}")
            logger.info(f"Projects result.data length: {len(result.data) if result.data else 'None'}")
        else:
            logger.error(f"Projects result object has no 'data' attribute")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if not result.data:
            logger.info(f"No projects found for user: {user_id}")
            return []
        
        # æ ¼å¼åŒ–è¿”å›æ•°æ®
        projects = []
        logger.info(f"ğŸ”„ Processing {len(result.data)} raw projects")
        
        for i, project in enumerate(result.data):
            logger.info(f"Processing project {i+1}: {project.get('project_id', 'no-id')}")
            
            # å¤„ç†sandboxå­—æ®µï¼Œç¡®ä¿åŒ…å«å¿…éœ€çš„å­—æ®µ
            sandbox_config = project.get("sandbox", {})
            if not isinstance(sandbox_config, dict):
                sandbox_config = {}
            
            # ç¡®ä¿sandboxåŒ…å«æ‰€éœ€å­—æ®µ
            sandbox = {
                "id": sandbox_config.get("id", ""),
                "pass": sandbox_config.get("pass", ""), 
                "vnc_preview": sandbox_config.get("vnc_preview", ""),
                "sandbox_url": sandbox_config.get("sandbox_url", "")
            }
            
            # å¤„ç†metadataä¸­çš„is_publicå­—æ®µ
            metadata = project.get("metadata", {})
            if not isinstance(metadata, dict):
                metadata = {}
            
            formatted_project = {
                "id": project["project_id"],  # æ˜ å°„project_idä¸ºid
                "name": project["name"],
                "description": project.get("description", ""),
                "account_id": project["account_id"],
                "created_at": project["created_at"],
                "updated_at": project["updated_at"],
                "sandbox": sandbox,
                "is_public": metadata.get("is_public", False)  # ä»metadataä¸­è·å–æˆ–é»˜è®¤ä¸ºFalse
            }
            projects.append(formatted_project)
        
        logger.info(f"Final projects count: {len(projects)}")
        logger.info(f"Final projects type: {type(projects)}")
        
        logger.info(f"Successfully found {len(projects)} projects for user: {user_id}")
        return projects
        
    except Exception as e:
        logger.error(f"Error getting projects for user {user_id}: {e}")
        logger.error(f"Exception type: {type(e)}")
        logger.error(f"Exception traceback:", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to get projects: {str(e)}")

@api_router.get("/sidebar/threads")
async def get_threads(user_id: str = Depends(get_current_user_id_from_jwt)):
    """get threads for sidebar"""
    try:
        logger.info(f"Getting threads for user: {user_id}")
        
        # è·å–æ•°æ®åº“å®¢æˆ·ç«¯
        client = await db.client
        
        # æŸ¥è¯¢ç”¨æˆ·çš„çº¿ç¨‹åˆ—è¡¨ï¼Œè¿‡æ»¤æ‰is_agent_builder=trueçš„çº¿ç¨‹
        logger.info(f"Querying threads table for account_id: {user_id}")
        result = await client.table("threads").select("*").eq("account_id", user_id).order("created_at", desc=True).execute()
        
        
        if hasattr(result, 'data'):
            logger.info(f"Result.data length: {len(result.data) if result.data else 'None'}")
        else:
            logger.error(f"Result object has no 'data' attribute")
            logger.error(f"Result attributes: {dir(result)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if not result.data:
            logger.info(f"No threads found for user: {user_id}")
            return []
        
        # æ ¼å¼åŒ–è¿”å›æ•°æ®å¹¶è¿‡æ»¤
        threads = []
        logger.info(f"Processing {len(result.data)} raw threads")
        
        for i, thread in enumerate(result.data):
            logger.info(f"Processing thread {i+1}: {thread.get('thread_id', 'no-id')}")
            
            # å¤„ç†metadataå­—æ®µ
            metadata = thread.get("metadata", {})
            if not isinstance(metadata, dict):
                logger.info(f"Converting metadata from {type(metadata)} to dict")
                metadata = {}
            
            logger.info(f"Thread metadata: {metadata}")
            
            # è¿‡æ»¤æ‰is_agent_builderä¸ºtrueçš„çº¿ç¨‹
            if metadata.get("is_agent_builder") == True:
                logger.info(f"Skipping thread {thread.get('thread_id')} - is_agent_builder=true")
                continue
                
            formatted_thread = {
                "id": thread["thread_id"],  # æ˜ å°„thread_idä¸ºid
                "name": thread.get("name", ""),
                "project_id": thread["project_id"],
                "account_id": thread["account_id"],
                "status": thread.get("status", "active"),
                "metadata": metadata,
                "created_at": thread["created_at"],
                "updated_at": thread["updated_at"]
            }
            
            threads.append(formatted_thread)
        
        
        logger.info(f"Successfully found {len(threads)} threads for user: {user_id}")
        return threads
        
    except Exception as e:
        logger.error(f"Error getting threads for user {user_id}: {e}")
        logger.error(f"Exception type: {type(e)}")
        logger.error(f"Exception traceback:", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to get threads: {str(e)}")

@api_router.get("/health")
async def health_check():
    logger.info("Health check endpoint called")
    return {
        "status": "ok", 
        "timestamp": datetime.now(timezone.utc).isoformat(),
        # "instance_id": instance_id
    }

# æ·»åŠ å…¨å±€ OPTIONS å¤„ç†å™¨æ¥è§£å†³ CORS é—®é¢˜
@app.options("/{path:path}")
async def options_handler(request: Request, path: str):
    """å¤„ç†æ‰€æœ‰çš„ OPTIONS è¯·æ±‚ï¼ˆCORS é¢„æ£€ï¼‰"""
    logger.info(f"ğŸ” [CORS] OPTIONS /{path} called")
    logger.info(f"ğŸ” [CORS] Headers: {dict(request.headers)}")
    
    from fastapi.responses import Response
    response = Response(status_code=200)
    response.headers["Access-Control-Allow-Origin"] = "*"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS, PATCH"
    response.headers["Access-Control-Allow-Headers"] = "*"
    response.headers["Access-Control-Max-Age"] = "86400"
    
    logger.info(f"âœ… [CORS] Returning CORS preflight response for /{path}")
    return response

@api_router.get("/health-docker")
async def health_check_docker():
    """Dockerå¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼Œæµ‹è¯•æ•°æ®åº“å’ŒRedisè¿æ¥"""
    logger.info("Dockerå¥åº·æ£€æŸ¥ç«¯ç‚¹è¢«è°ƒç”¨")
    try:
        # æµ‹è¯•Redisè¿æ¥
        from services import redis
        client = await redis.get_client()
        await client.ping()
        
        # æµ‹è¯•æ•°æ®åº“è¿æ¥
        db_instance = DBConnection()
        await db_instance.initialize()
        db_client = await db_instance.client
        # å°è¯•æŸ¥è¯¢ä¸€ä¸ªç®€å•çš„è¡¨æ¥æµ‹è¯•è¿æ¥
        await db_client.table("auth_users").select("id").limit(1).execute()
        
        logger.info("Dockerå¥åº·æ£€æŸ¥å®Œæˆ")
        return {
            "status": "ok", 
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "instance_id": instance_id,
            "database": "connected",
            "redis": "connected"
        }
    except Exception as e:
        logger.error(f"Dockerå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")


app.include_router(api_router, prefix="/api")


if __name__ == "__main__":
    import uvicorn
    
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    workers = 4
    
    logger.info(f"Starting server on 0.0.0.0:8000 with {workers} workers")
    uvicorn.run(
        "api:app", 
        host="0.0.0.0", 
        port=8000,
        workers=workers,
        loop="asyncio",
        reload=True
    )